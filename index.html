<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Sentinel-2</title>
    <meta charset="utf-8" />
    <meta name="author" content="Rahmadita Listianingrum" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <script src="libs/js-cookie/js.cookie.js"></script>
    <script src="libs/peerjs/peerjs.min.js"></script>
    <script src="libs/tiny.toast/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast/broadcast.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/mark.js/mark.min.js"></script>
    <link href="libs/xaringanExtra-search/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":true,"autoSearch":false}) })</script>
    <script src="libs/xaringanExtra-progressBar/progress-bar.js"></script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding/datatables.js"></script>
    <script src="libs/jquery/jquery-3.6.0.min.js"></script>
    <link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Sentinel-2
]
.subtitle[
## The Remote Sensing Sensor
]
.author[
### Rahmadita Listianingrum
]
.date[
### 2023/01/27
]

---

class: center middle






<style>.xe__progress-bar__container {
  bottom:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #FFC94A;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>



&lt;center&gt;&lt;img src="https://www.earthdata.nasa.gov/s3fs-public/2022-02/Air-Quality-Transparent-Blue.gif?VersionId=z3k6nWjVZXyNXN30iMu4GZnVDBVqHYZ0" alt="Sensor" height="300px" /&gt;&lt;/center&gt;
.bg-.b--yellow.ba.bw2.br2.shadow-2.ph3.mt3[
## "Remote sensing is the acquiring of information from a distance."
.tr[
**â€” NASA**
]]

---
class: inverse center middle

# Summary

Earth Observation mission from the Copernicus Programme

---

## Sentinel-2

.panelset[
.panel[.panel-name[**Sentinel-2**]

&lt;img src="img/sentinel-2.png" width="50%" style="display: block; margin: auto;" /&gt;
Source: [ESA](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2) &lt;a name=cite-esaSentinel2MissionsSentinel&gt;&lt;/a&gt;([ESA, 2023](#bib-esaSentinel2MissionsSentinel))

]

.panel[.panel-name[**Overview**]

.pull-left[

SENTINEL-2 is a high-resolution, multi-spectral imaging mission consisting of two twin satellites in the same orbit with a high revisit frequency of 5 days at the Equator. The satellites carry an optical instrument payload that samples 13 spectral bands at different spatial resolutions, providing an orbital swath width of 290 km. The SENTINEL-2 mission continues the legacy of SPOT and LANDSAT and supports various services and applications offered by Copernicus, including land management, agriculture, forestry, disaster control, humanitarian relief operations, risk mapping, and security concerns.

]

.pull-right[

&lt;img src="img/sentinel-2-sat.png" width="100%" style="display: block; margin: auto;" /&gt;
Source: [Astrium GmBH, Germany](https://artes.esa.int/contractors/eads-astrium-gmbh)&lt;a name=cite-eadsEADSAstriumGmbH&gt;&lt;/a&gt;([EADS, 2023](#bib-eadsEADSAstriumGmbH))

]
]

.panel[.panel-name[**Key-Features**]

.pull-left[

Sentinel is the [Earth Observation](https://joint-research-centre.ec.europa.eu/scientific-activities-z/earth-observation_en) mission from the [Copernicus Programme](https://www.copernicus.eu/en/about-copernicus) 

The SENTINEL-2 satellite aims to provide high-resolution, multispectral images with a high revisit frequency on a global scale. Its objectives are outlined in the Mission Requirements Document and include providing continuity for multi-spectral imagery from SPOT and LANDSAT satellites, generating data for operational products like land-cover maps, and contributing to Copernicus themes like climate change and land monitoring. With its 13 spectral bands, 290 km swath width, and high revisit frequency, SENTINEL-2's MSI instrument is well-suited for a range of land studies and programmes, including land cover/change classification, atmospheric correction, and cloud/snow masks.

]

.pull-right[

&lt;img src="img/key-features.png" width="100%" style="display: block; margin: auto;" /&gt;
Source: [Astrium GmBH, Germany](https://artes.esa.int/contractors/eads-astrium-gmbh)([EADS, 2023](#bib-eadsEADSAstriumGmbH))

]
]

.panel[.panel-name[**Comparison**]

&lt;img src="img/comparison.png" width="55%" style="display: block; margin: auto;" /&gt;
Comparison of the capabilities of Landsat, SPOT and Sentinel-2.&lt;br&gt;
Source: [Astrium GmBH, Germany](https://artes.esa.int/contractors/eads-astrium-gmbh)([EADS, 2023](#bib-eadsEADSAstriumGmbH))

]

.panel[.panel-name[**Bands**]

&lt;style&gt;
div.remark-slide-content {
  padding: 2em; /*default is 1em 4em*/
  font-size: .6em;
}
&lt;/style&gt;




<div id="htmlwidget-6ce7449a42f76bf2e7b9" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6ce7449a42f76bf2e7b9">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13"],["Coastal aerosol","Blue","Green","Red","Vegetation Red Edge","Vegetation Red Edge","Vegetation Red Edge","NIR","Narrow NIR","Water Vapour","SWIR - Cirrus","SWIR","SWIR"],["MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI","MSI"],[1,2,3,4,5,6,7,8,9,10,11,12,13],[443.9,496.6,560,664.5,703.9,740.2,782.5,835.1,864.8,945,1373.5,1613.7,2202.4],[20,65,35,30,15,15,20,115,20,20,30,90,180],[442.3,492.1,559,665,703.8,739.1,779.7,833,864,943.2,1376.9,1610.4,2185.7],[20,65,35,30,15,15,20,115,20,20,30,90,180],[60,10,10,10,20,20,20,10,20,60,60,20,20]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Bands<\/th>\n      <th>Sensor<\/th>\n      <th>Number<\/th>\n      <th>Sentinel-2A<\/th>\n      <th>Number-Central Wavelength (nm)<\/th>\n      <th>Sentinel-2B Bandwidth (nm)<\/th>\n      <th>Central wavelength (nm)-2<\/th>\n      <th>Resolution (meters)-Bandwith (nm)-2<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[3,4,5,6,7,8]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background':'white','angle':'-90','background-size':'98% 88%','background-repeat':'no-repeat','background-position':'center'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>

Source: [EOS Data Analytics](https://eos.com/find-satellite/sentinel-2/)&lt;a name=cite-eosSentinel2SatelliteImagery2021&gt;&lt;/a&gt;([EOS, 2023](#bib-eosSentinel2SatelliteImagery2021))
]
]

---

class: inverse center middle

# Application

---

## Marine/Coastal Monitoring

The study by Yustisi Lumban-Gaol, Ken Arroyo Ohori, and Ravi Peters, published in Marine Geodesy in 2022, extracted water depth information in coastal areas using multi-temporal Sentinel-2 satellite images and convolutional neural networks (CNNs). The study is motivated by the importance of water depth information for various applications, such as navigation safety, coastal zone management, and ecosystem conservation. &lt;a name=cite-lumban-gaolExtractingCoastalWater2022&gt;&lt;/a&gt;([Lumban-Gaol, Ohori, and Peters, 2022](#bib-lumban-gaolExtractingCoastalWater2022)) used a CNN model architecture that consists of two convolutional layers followed by two fully connected layers. The input to the CNN model is a multi-temporal Sentinel-2 image, and the output is a water depth map. The authors also experimented with different input combinations of Sentinel-2 bands, temporal differences, and spatial filters to optimize the performance of the CNN model. The accuracy of the depth estimates achieved in this study is promising for applications such as navigation safety and coastal zone management. The authors suggest that further research can explore the application of the CNN models to other coastal areas with different water properties and bathymetric characteristics.

.pull-left[

&lt;img src="img/result1.png" width="55%" style="display: block; margin: auto;" /&gt;
Source: ([Lumban-Gaol, Ohori, and Peters, 2022](#bib-lumban-gaolExtractingCoastalWater2022))

]

.pull-right[

&lt;img src="img/error1.png" width="75%" style="display: block; margin: auto;" /&gt;
Source: ([Lumban-Gaol, Ohori, and Peters, 2022](#bib-lumban-gaolExtractingCoastalWater2022))

]

---
class: inverse center middle

# Reflection

---

## Reflection

it is clear that Sentinel-2 is a powerful tool for various applications such as land cover mapping, vegetation monitoring, and water quality assessment. Its multi-spectral imaging capability and high spatial resolution provide valuable data for research and analysis. The study you mentioned on extracting coastal water depths using Sentinel-2 images is a great example of the satellite's potential for oceanographic applications.

The study of Sentinel-2 application demonstrates how the use of convolutional neural networks (CNNs) can extract information on coastal water depths from Sentinel-2 images with high accuracy. This approach can provide a cost-effective and efficient way of collecting data on coastal bathymetry, which is essential for a variety of marine applications such as coastal zone management, fisheries management, and environmental monitoring.

The capabilities of Sentinel-2 and the advancements in image processing techniques, such as CNNs, have allowed for new insights and opportunities in remote sensing applications. The increasing availability of high-quality satellite data has the potential to revolutionize our understanding of the natural world and inform policy and decision-making.

---

# Reference

&lt;a name=bib-eadsEADSAstriumGmbH&gt;&lt;/a&gt;[EADS, A.
G.](#cite-eadsEADSAstriumGmbH) (2023). _EADS Astrium GmbH_. URL:
[https://artes.esa.int/contractors/eads-astrium-gmbh](https://artes.esa.int/contractors/eads-astrium-gmbh)
(visited on Mar. 24, 2023).

&lt;a name=bib-eosSentinel2SatelliteImagery2021&gt;&lt;/a&gt;[EOS,
E.](#cite-eosSentinel2SatelliteImagery2021) (2023). _Sentinel-2:
Satellite Imagery, Overview, And Characteristics_. URL:
[https://eos.com/find-satellite/sentinel-2/](https://eos.com/find-satellite/sentinel-2/)
(visited on Mar. 24, 2023).

&lt;a name=bib-esaSentinel2MissionsSentinel&gt;&lt;/a&gt;[ESA,
E.](#cite-esaSentinel2MissionsSentinel) (2023). _Sentinel-2 - Missions
- Sentinel Online_. URL:
[https://copernicus.eu/missions/sentinel-2](https://copernicus.eu/missions/sentinel-2)
(visited on Mar. 24, 2023).

&lt;a name=bib-lumban-gaolExtractingCoastalWater2022&gt;&lt;/a&gt;[Lumban-Gaol, Y.,
K. A. Ohori, and R.
Peters](#cite-lumban-gaolExtractingCoastalWater2022) (2022).
"Extracting Coastal Water Depths from Multi-Temporal Sentinel-2 Images
Using Convolutional Neural Networks". In: _Marine Geodesy_ 45.6, pp.
615-644. ISSN: 0149-0419. DOI:
[10.1080/01490419.2022.2091696](https://doi.org/10.1080%2F01490419.2022.2091696).
URL:
[https://doi.org/10.1080/01490419.2022.2091696](https://doi.org/10.1080/01490419.2022.2091696)
(visited on Mar. 24, 2023).

---
class: inverse center middle

# Thanks!

Slides created via the R packages:

[**xaringan**](https://github.com/yihui/xaringan) by&lt;br&gt;[**Yihui Xi**](https://yihui.org)&lt;br&gt;
[**xaringanthemer**](https://github.com/gadenbuie/xaringanthemer) and
[**xaringanExtra**](https://github.com/gadenbuie/xaringanExtra) by&lt;br&gt;[**Garrick Aden Buie**](https://www.garrickadenbuie.com)

This slide is inspired by and adapted from&lt;br&gt;[**Dr Andrew Maclachlan's lecture**](https://andrewmaclachlan.github.io/CASA0023-lecture-2/#1)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
